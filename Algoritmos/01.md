# Algoritmos

## Principios para Analizar Algoritmos

### Principio #1

- Análisis pesimista: el tiempo de ejecución que calculemos vale para cualquier input posible si calculamos el peor caso posible de largo n. A diferencia de los otros 2, no requiere conocer el dominio de la rutina.

- Caso promedio: Asumir la frecuencia de ciertos inputs, analizar tiempo promedio.

- Benchmark: Convención de inputs.

### Principio #2

No prestar mucha atención a los factores constantes.

- Más fácil.

- Depende de la implementación, compilador, arquitectura, etc.

- Muy poca diferencia para predecir performance.

### Principio #3

Análisis asintótico: Concentrarse en tiempo de ejecución para inputs *grandes* de n.

Ejemplo: $6n\log_2(n)+6n$ es "mejor que" $1/2n^2$, es decir, es mejor para valores suficientemente grandes de n.

## Análisis Asintótico

Vocabulario usado para el diseño y análisis de algoritmos. Nos permite simplificar detalles de implementación, pero complejizar comparaciones predictivas entre algoritmos distintos, especialmente con inputs grandes.

En resumen: Buscamos *suprimir factores constantes y términos de nivel inferior*.

Ejemplo: Tratamos como equivalentes a $6n \log_2(n)$ + 6n con n log n. Entonces, Merge Sort es un algoritmos O(n log(n)), donde n es el tamaño del input.

## Notación $O()$

Definición: $T(n)=O(f(n))$ si y sólo si existen constantes $c,n_0>0$ tal que $T(n)\le c*f(n)$, para todo $n\ge n_0$ (con $c,n_0$ independiente de $n$).

## Propiedades/Ejemplos

1) Si $T(n)$ es un polinomio de grado $k$, lo único que nos importa es ese n de grado más alto: $T(n)=O(n^k)$. Es decir, descartamos las constantes.

2) Para todo $k>=1$, $n^k$ no es $O(N^{k-1})$.

## Notación $\Omega$ y $\Theta$

- Omega: $T(n)=\Omega(f(n))$ si y sólo si existen constantes $c,n0$ tales que $T(n)\ge c\cdot f(n)\forall n\ge n_0$.

- Theta: $T(n)=\Theta (f(n))$ si y sólo si $T(n)=O(f(n))$ y $T(n)=\Omega (f(n))$. Equivalente: Existen constantes $c_1,c_2,n_0$ tales que $c_1f(n)\le T(n)\le c_2f(n)$.

## Notación $o$

Definición: $T(n)=o(f(n))$ si y sólo si para *todas* las constantes $c>0$, existe una constante $n_0$ tal que $T(n)\le c\cdot f(n),\forall n\ge n_0$.
